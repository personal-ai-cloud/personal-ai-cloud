from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse
import os
import json
from openai import OpenAI

# ----------------------------
# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡
# ----------------------------
app = FastAPI()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

MEMORY_FILE = "memory.json"

# ----------------------------
# ØªÙˆØ§Ø¨Ø¹ Ø­Ø§ÙØ¸Ù‡
# ----------------------------
def load_memory():
    if not os.path.exists(MEMORY_FILE):
        return {"name": ""}
    with open(MEMORY_FILE, "r", encoding="utf-8") as f:
        return json.load(f)

def save_memory(memory):
    with open(MEMORY_FILE, "w", encoding="utf-8") as f:
        json.dump(memory, f, ensure_ascii=False, indent=2)

# ----------------------------
# ØªØ³Øª Ø³Ù„Ø§Ù…Øª Ø³Ø±ÙˆØ±
# ----------------------------
@app.get("/")
def root():
    return {"status": "AI is running"}

# ----------------------------
# Ú†Øª Ø¨Ø§ Ø­Ø§ÙØ¸Ù‡ Ø´Ø®ØµÛŒ
# ----------------------------
@app.post("/chat")
async def chat(request: Request):
    data = await request.json()
    user_message = data.get("message", "").strip()

    memory = load_memory()

    # Ø§Ú¯Ø± Ø§Ø³Ù… Ø°Ø®ÛŒØ±Ù‡ Ù†Ø´Ø¯Ù‡
    if memory["name"] == "":
        memory["name"] = user_message
        save_memory(memory)
        return JSONResponse({
            "reply": f"Ø®ÛŒÙ„ÛŒ Ø®ÙˆØ´ÙˆÙ‚ØªÙ… {memory['name']} ğŸ˜Š Ø§Ø² Ø§ÛŒÙ† Ø¨Ù‡ Ø¨Ø¹Ø¯ Ø´Ù…Ø§ Ø±Ùˆ Ø¨Ù‡ Ø®Ø§Ø·Ø± Ù…ÛŒâ€ŒØ³Ù¾Ø§Ø±Ù…."
        })

    user_name = memory["name"]

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {
                "role": "system",
                "content": f"You are a helpful personal AI assistant. The user's name is {user_name}."
            },
            {
                "role": "user",
                "content": user_message
            }
        ]
    )

    return JSONResponse({
        "reply": response.choices[0].message.content
    })
